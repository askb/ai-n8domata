# Only keep traefik volume since it still uses named volume
volumes:
  traefik_data:

networks:
  n8n-network:
    driver: bridge

x-n8n: &service-n8n
  build:
    context: .
    dockerfile: Dockerfile
  profiles:
    - core
  user: root:root
  restart: unless-stopped
  networks:
    - n8n-network
  environment:
    - N8N_DIAGNOSTICS_ENABLED=${N8N_DIAGNOSTICS_ENABLED}
    - N8N_USER_FOLDER=${N8N_USER_FOLDER}
    - N8N_SECURE_COOKIE=${N8N_SECURE_COOKIE}
    - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=${N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS}
    - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
    - N8N_HOST=${N8N_HOST}
    - N8N_PROTOCOL=${N8N_PROTOCOL}
    - N8N_WEBHOOK=${N8N_WEBHOOK}
    - N8N_WEBHOOK_URL=${N8N_WEBHOOK_URL}
    - WEBHOOK_URL=${WEBHOOK_URL}
    - N8N_EDITOR_BASE_URL=${N8N_EDITOR_BASE_URL}
    # Queue mode config
    - EXECUTIONS_MODE=${EXECUTIONS_MODE}
    - QUEUE_BULL_REDIS_HOST=${QUEUE_BULL_REDIS_HOST}
    - QUEUE_HEALTH_CHECK_ACTIVE=${QUEUE_HEALTH_CHECK_ACTIVE}
    - N8N_QUEUE_BULL_GRACEFULSHUTDOWNTIMEOUT=${N8N_QUEUE_BULL_GRACEFULSHUTDOWNTIMEOUT}
    - N8N_GRACEFUL_SHUTDOWN_TIMEOUT=${N8N_GRACEFUL_SHUTDOWN_TIMEOUT}
    # DB config
    - DB_TYPE=${DB_TYPE}
    - DB_POSTGRESDB_HOST=${POSTGRES_HOST}
    - DB_POSTGRESDB_DATABASE=${POSTGRES_DB}
    - DB_POSTGRESDB_USER=${POSTGRES_USER}
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
    # Task Runner config
    - OFFLOAD_MANUAL_EXECUTIONS_TO_WORKERS=${OFFLOAD_MANUAL_EXECUTIONS_TO_WORKERS}
    - N8N_RUNNERS_AUTH_TOKEN=${N8N_RUNNERS_AUTH_TOKEN}
    - N8N_TASK_BROKER_URL=${N8N_TASK_BROKER_URL}
    - N8N_COMMAND_RESPONSE_URL=${N8N_COMMAND_RESPONSE_URL}
    - N8N_TASK_BROKER_PORT=${N8N_TASK_BROKER_PORT}
    - NODE_FUNCTION_ALLOW_EXTERNAL=ajv,ajv-formats,puppeteer
    - PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium
    # BINARY DATA CONFIGURATION - ADD THESE LINES
    - N8N_DEFAULT_BINARY_DATA_MODE=filesystem
    - N8N_BINARY_DATA_TTL=1440
    - N8N_BINARY_DATA_STORAGE_PATH=/home/node/.n8n/binaryData

services:
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: n8n-cloudflared
    restart: unless-stopped
    networks:
      - n8n-network
    command: tunnel --no-autoupdate run --token ${CLOUDFLARE_TUNNEL_TOKEN}
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
    profiles:
      - core

  traefik:
    image: traefik:v2.10
    container_name: n8n-traefik
    restart: unless-stopped
    networks:
      - n8n-network
    profiles:
      - core
    command:
      - "--api=true"
      - "--api.dashboard=true"
      - "--providers.docker=true"
      - "--api.insecure=true"
      - "--providers.docker.exposedbydefault=false"
      # CLOUDFLARE TUNNEL SETUP - Only HTTP needed (Cloudflare handles SSL)
      - "--entrypoints.web.address=:80"
      # Keep existing N8N specific entrypoints
      - "--entrypoints.n8n_ui.address=:8082"
      - "--entrypoints.n8n_webhooks.address=:8083"
      # Enable access logs for debugging
      - "--accesslog=true"
      - "--log.level=INFO"
    ports:
      - "80:80"           # Only HTTP needed for Cloudflare Tunnel
      - "8082:8082"       # N8N UI
      - "8083:8083"       # N8N webhooks
      - "8081:8080"       # Traefik dashboard
    volumes:
      - traefik_data:/letsencrypt
      - /var/run/docker.sock:/var/run/docker.sock:ro
    labels:
      # Basic Traefik dashboard
      - "traefik.enable=true"
      - "traefik.http.routers.dashboard.rule=Host(`${TRAEFIK_HOST}`) || Host(`localhost`)"
      - "traefik.http.routers.dashboard.entrypoints=web"
      - "traefik.http.routers.dashboard.service=api@internal"
      # Security headers middleware
      - "traefik.http.middlewares.secure-headers.headers.framedeny=true"
      - "traefik.http.middlewares.secure-headers.headers.contenttypenosniff=true"
      - "traefik.http.middlewares.secure-headers.headers.browserxssfilter=true"
      - "traefik.http.middlewares.secure-headers.headers.customrequestheaders.X-Forwarded-Proto=https"
      # Rate limiting middleware (100 requests/second average, 200 burst)
      - "traefik.http.middlewares.rate-limit.ratelimit.average=100"
      - "traefik.http.middlewares.rate-limit.ratelimit.burst=200"
      # IP whitelist middleware (replace with your IP)
      - "traefik.http.middlewares.ip-whitelist.ipwhitelist.sourcerange=${IP_WHITELIST_RANGE}"

  redis:
    image: redis:7-alpine
    container_name: n8n-redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
    profiles:
      - core
    volumes:
      - ./backups/redis:/data
    networks:
      - n8n-network

  postgres:
    image: postgres:17
    container_name: n8n-postgres
    restart: unless-stopped
    profiles:
      - core
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=${PGDATA}
      - POSTGRES_HOST_AUTH_METHOD=scram-sha-256
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256 --auth-local=scram-sha-256
    volumes:
      - ./postgres-data/pgdata:/var/lib/postgresql/data/pgdata
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - n8n-network

  n8n:
    <<: *service-n8n
    container_name: n8n-main
    ports:
      - "5678:5678"
      - "5679:5679"
    volumes:
      - ./backups/n8n-data:/n8n
      - ./backups/n8n-workflows:/home/node/.n8n/workflows
      - ./backups/n8n-credentials:/home/node/.n8n/credentials
      - ./backups/n8n-binary:/home/node/.n8n/binaryData  # ADD THIS LINE
      - ./videos:/app/data/videos:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - n8n-network
    healthcheck:
      test: ["CMD", "node", "-v"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 60s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.n8n-ui.rule=Host(`${N8N_HOST}`)"
      - "traefik.http.routers.n8n-ui.entrypoints=n8n_ui"
      - "traefik.http.routers.n8n-webhooks.rule=Host(`${N8N_WEBHOOK}`)"
      - "traefik.http.routers.n8n-webhooks.entrypoints=n8n_webhooks"
      - "traefik.http.services.n8n.loadbalancer.server.port=5678"

  n8n-webhook:
    <<: *service-n8n
    container_name: n8n-webhook
    command: sh /webhook
    volumes:
      - ./backups/n8n-data:/n8n
      - ./backups/n8n-binary:/home/node/.n8n/binaryData
    depends_on:
      n8n:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - n8n-network

  n8n-worker:
    <<: *service-n8n
    container_name: n8n-worker
    stop_grace_period: 5m
    command: sh /worker
    volumes:
      - ./backups/n8n-data:/n8n
      - ./backups/n8n-binary:/home/node/.n8n/binaryData
    depends_on:
      n8n:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - n8n-network
    healthcheck:
      test: ["CMD", "node", "-v"]
      interval: 5s
      timeout: 5s
      retries: 10

  queue-metrics:
    build:
      context: .
      dockerfile: queue-metrics/Dockerfile.queue-metrics
    container_name: n8n-queue-metrics
    profiles:
      - core
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - n8n-network
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - QUEUE_NAME_PREFIX=${QUEUE_NAME_PREFIX}
      - QUEUE_NAME=${QUEUE_NAME}
      - POLL_INTERVAL_SECONDS=${POLL_INTERVAL_SECONDS}

  dynamic-scaler:
    build:
      context: .
      dockerfile: dynamic-scaler/Dockerfile.dynamic-scaler
      args:
        - REDIS_HOST=${REDIS_HOST}
        - REDIS_PORT=${REDIS_PORT}
        - QUEUE_NAME_PREFIX=${QUEUE_NAME_PREFIX}
        - QUEUE_NAME=${QUEUE_NAME}
        - N8N_WORKER_SERVICE_NAME=${N8N_WORKER_SERVICE_NAME}
        - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME}
    container_name: n8n-dynamic-scaler
    profiles:
      - core
    restart: unless-stopped
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - QUEUE_NAME_PREFIX=${QUEUE_NAME_PREFIX}
      - QUEUE_NAME=${QUEUE_NAME}
      - N8N_WORKER_SERVICE_NAME=${N8N_WORKER_SERVICE_NAME}
      - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME}
      - COMPOSE_FILE_PATH=/app/docker-compose.yml
      - MIN_REPLICAS=${MIN_REPLICAS}
      - MAX_REPLICAS=${MAX_REPLICAS}
      - SCALE_UP_QUEUE_THRESHOLD=${SCALE_UP_QUEUE_THRESHOLD}
      - SCALE_DOWN_QUEUE_THRESHOLD=${SCALE_DOWN_QUEUE_THRESHOLD}
      - POLLING_INTERVAL_SECONDS=${POLLING_INTERVAL_SECONDS}
      - COOLDOWN_PERIOD_SECONDS=${COOLDOWN_PERIOD_SECONDS}
      - NODE_FUNCTION_ALLOW_EXTERNAL=ajv,ajv-formats,puppeteer
      - PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium
      - N8N_QUEUE_BULL_GRACEFULSHUTDOWNTIMEOUT=${N8N_QUEUE_BULL_GRACEFULSHUTDOWNTIMEOUT}
      - N8N_GRACEFUL_SHUTDOWN_TIMEOUT=${N8N_GRACEFUL_SHUTDOWN_TIMEOUT}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./.env:/app/.env
    depends_on:
      redis:
        condition: service_healthy
      n8n-worker:
        condition: service_started
    networks:
      - n8n-network

  n8n-backup:
    image: alpine:latest
    container_name: n8n-backup
    restart: unless-stopped
    profiles:
      - core
    networks:
      - n8n-network
    volumes:
      - ./backups:/source
      - ./daily-backups:/backups
    environment:
      - TZ=UTC
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    command: >
      sh -c "
        echo 'Installing required packages...'
        apk add --no-cache tar gzip findutils coreutils postgresql-client
        echo 'Starting backup service...'
        while true; do
          echo 'Creating backup at: $$(date)'
          BACKUP_DATE=$$(date +%Y%m%d-%H%M%S)
          DUMP_FILE="/source/dump-$$BACKUP_DATE.sql"

          echo 'Dumping database...'
          export PGPASSWORD=$$POSTGRES_PASSWORD
          pg_dump -h postgres -U $$POSTGRES_USER -d $$POSTGRES_DB -f $$DUMP_FILE

          if [ $$? -eq 0 ]; then
            echo 'Database dump successful. Creating archive...'
            tar -czf /backups/n8n-full-backup-$$BACKUP_DATE.tar.gz -C /source n8n-credentials n8n-workflows n8n-data $$(basename $$DUMP_FILE)

            if [ $$? -eq 0 ]; then
                echo 'Backup created successfully.'
            else
                echo 'Archive creation failed!'
            fi

            echo 'Cleaning up dump file...'
            rm $$DUMP_FILE
          else
            echo 'Database dump failed!'
          fi

          echo 'Cleaning up old backups...'
          find /backups -name 'n8n-full-backup-*.tar.gz' -mtime +7 -delete

          echo 'Next backup in 24 hours'
          sleep 86400
        done
      "
    depends_on:
      - postgres
      - n8n

  short-video-maker-cpu:
    image: gyoridavid/short-video-maker:latest-tiny
    container_name: n8n-short-video-maker-cpu
    restart: unless-stopped
    profiles:
      - core
    networks:
      - n8n-network
    environment:
      - LOG_LEVEL=error
      - PEXELS_API_KEY=${PEXELS_API_KEY}
    volumes:
      - ./videos:/app/data/videos
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3123/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.short-video-maker.rule=Host(`${SHORT_VIDEO_MAKER_HOST}`)"
      - "traefik.http.routers.short-video-maker.entrypoints=web"
      - "traefik.http.routers.short-video-maker.service=short-video-maker"
      - "traefik.http.services.short-video-maker.loadbalancer.server.port=3123"

  ai-agent-cpu:
    image: gyoridavid/ai-agents-no-code-tools:latest
    container_name: n8n-ai-agent-cpu
    restart: unless-stopped
    profiles:
      - core
    networks:
      - n8n-network
    ports:
      - "8008:8000"
    environment:
      # Basic configuration
      - LOG_LEVEL=error
      - PYTHONUNBUFFERED=1
      # Force CPU mode
      - CUDA_VISIBLE_DEVICES=""
      - PYTORCH_DISABLE_CUDA=1
      - TORCH_DEVICE=cpu
    volumes:
      - ./caches/ai-agent-pip:/root/.cache/pip:rw
      - ./services/ai-agent-no-code-tools-requirements.txt:/tmp/requirements.txt:ro
      - ./videos:/app/media/video
    command: |
      sh -c "
        echo 'Installing additional dependencies...'
        pip install --no-cache-dir -r /tmp/requirements.txt
        echo 'Dependencies installed, starting server...'
        exec fastapi run server.py --host 0.0.0.0 --port 8000
      "
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: "8.0"
        reservations:
          memory: 2G
          cpus: "1.0"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8008/docs"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.ai-agent-cpu.rule=Host(`${AI_AGENT_HOST}`)"
      - "traefik.http.routers.ai-agent-cpu.entrypoints=web"
      - "traefik.http.routers.ai-agent-cpu.service=ai-agent-cpu"
      - "traefik.http.services.ai-agent-cpu.loadbalancer.server.port=8000"

  miniio:
    image: quay.io/minio/minio:RELEASE.2025-04-22T22-12-26Z
    container_name: n8n-miniio
    restart: unless-stopped
    profiles:
      - core
    networks:
      - n8n-network
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./data/minio:/data
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.minio-api.rule=Host(`${MINIO_API_HOST}`)"
      - "traefik.http.routers.minio-api.entrypoints=web"
      - "traefik.http.routers.minio-api.service=minio-api"
      - "traefik.http.services.minio-api.loadbalancer.server.port=9000"
      - "traefik.http.routers.minio-console.rule=Host(`${MINIO_CONSOLE_HOST}`)"
      - "traefik.http.routers.minio-console.entrypoints=web"
      - "traefik.http.routers.minio-console.service=minio-console"
      - "traefik.http.services.minio-console.loadbalancer.server.port=9001"

  kokoro-tts:
    image: ghcr.io/remsky/kokoro-fastapi-cpu:v0.2.2
    container_name: n8n-kokoro-tts
    restart: unless-stopped
    profiles:
      - core
    networks:
      - n8n-network
    ports:
      - "8880:8880"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8880/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.kokoro-tts.rule=Host(`${KOKORO_TTS_HOST}`)"
      - "traefik.http.routers.kokoro-tts.entrypoints=web"
      - "traefik.http.routers.kokoro-tts.service=kokoro-tts"
      - "traefik.http.services.kokoro-tts.loadbalancer.server.port=8880"

  baserow:
    image: baserow/baserow:1.32.5
    container_name: n8n-baserow
    restart: unless-stopped
    profiles:
      - core
    environment:
      BASEROW_PUBLIC_URL: ${BASEROW_PUBLIC_URL}
    networks:
      - n8n-network
    ports:
      - "85:80"
      - "443:443"
    volumes:
      - ./data/baserow:/baserow/data
    shm_size: 256mb
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.baserow.rule=Host(`${BASEROW_HOST}`)"
      - "traefik.http.routers.baserow.entrypoints=web"
      - "traefik.http.routers.baserow.service=baserow"
      - "traefik.http.services.baserow.loadbalancer.server.port=80"

  nca-toolkit:
    image: stephengpope/no-code-architects-toolkit:latest
    container_name: n8n-nca-toolkit
    restart: unless-stopped
    profiles:
      - core
    networks:
      - n8n-network
    ports:
      - "8080:8080"
    environment:
      API_KEY: ${NCAT_API_KEY}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL}
      S3_ACCESS_KEY: ${S3_ACCESS_KEY}
      S3_SECRET_KEY: ${S3_SECRET_KEY}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME}
      S3_REGION: ${S3_REGION}
      S3_PUBLIC_URL: ${S3_PUBLIC_URL}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.nca-toolkit.rule=Host(`${NCA_TOOLKIT_HOST}`)"
      - "traefik.http.routers.nca-toolkit.entrypoints=web"
      - "traefik.http.routers.nca-toolkit.service=nca-toolkit"
      - "traefik.http.services.nca-toolkit.loadbalancer.server.port=8080"

  intelligent-cropper:
    build:
      context: ./cropper
      dockerfile: Dockerfile
    container_name: n8n-intelligent-cropper
    restart: unless-stopped
    profiles:
      - core
    networks:
      - n8n-network
    ports:
      - "8888:8888"
    volumes:
      - ./videos:/app/videos
    environment:
      - PROCESSING_MODE=mediapipe
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.intelligent-cropper.rule=Host(`${CROPPER_HOST}`)"
      - "traefik.http.routers.intelligent-cropper.entrypoints=web"
      - "traefik.http.routers.intelligent-cropper.service=intelligent-cropper"
      - "traefik.http.services.intelligent-cropper.loadbalancer.server.port=8888"

  n8n-mcp:
    image: ghcr.io/czlonkowski/n8n-mcp:latest
    container_name: n8n-mcp-server
    restart: unless-stopped
    profiles:
      - core
    networks:
      - n8n-network
    environment:
      # Core MCP Configuration
      - MCP_MODE=stdio
      - LOG_LEVEL=error
      - DISABLE_CONSOLE_OUTPUT=true
      # N8N API Integration (Full Management Tools)
      - N8N_API_URL=http://n8n:5678
      - N8N_API_KEY=${N8N_API_KEY}
      # Enable Full N8N Management Features
      - ENABLE_WORKFLOW_MANAGEMENT=true
      - ENABLE_EXECUTION_MANAGEMENT=true
      - ENABLE_NODE_ANALYSIS=true
      - ENABLE_SYSTEM_TOOLS=true
      - ENABLE_VALIDATION_TOOLS=true
      # Performance and Caching
      - CACHE_WORKFLOWS=true
      - CACHE_NODES=true
      - MAX_WORKFLOW_SIZE=10MB
      # Security and Limits
      - VALIDATE_WORKFLOWS=true
      - MAX_EXECUTIONS_PER_QUERY=100
      - ENABLE_HEALTH_CHECKS=true
    stdin_open: true
    tty: true
    init: true
    depends_on:
      n8n:
        condition: service_healthy
    volumes:
      # Optional: Mount for configuration persistence
      - ./data/n8n-mcp-cache:/app/cache
    healthcheck:
      test: ["CMD", "node", "-e", "console.log('MCP Server Health Check')"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
